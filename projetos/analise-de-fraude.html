<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="style-banco.css">
    <link href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism-tomorrow.css" rel="stylesheet"/>
    <title>An√°lise de Fraude</title>
</head>
    <body>
        <header>
            <h1>Projeto de An√°lise de Fraude</h1>
            <p>Ci√™ncia de Dados</p>
            <span>Publicado em: EM DESENVOLVIMENTO</span>
        </header>

        <main>
            <!-- Descri√ß√£o do Projeto -->
            <section>
                <h2>Descri√ß√£o do Desafio</h2>
                <p>Projeto desenvolvido com Python para prever uma poss√≠vel transa√ß√£o fraudulenta.</p>
            </section>

            <!-- Bibliotecas-->
            <section>
                <h2>Bibliotecas</h2>
                <p>As ferramentas utilizadas no projeto foram:</p>
                <ul>
                    <li>Pandas: Para manipula√ß√£o e tratamento de dados;</li>
                    <li>Scikit-learn (sklearn): Biblioteca utilizada para taredas de Aprendizado de M√°quina (Machine Learning), incluindo Classifica√ß√£o, Regress√£o, entre  outros;</li>
                    <li>Streamlit: Facilita a constru√ß√£o da interface web;</li>
                    <li>Joblib: Serializa√ß√£o do Pipeline de ML treinado para uso posterior no aplicativo web.</li>
                </ul>

                <div class="code-container">
                    <pre><code class="language-python">import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import json
import itertools
import ast
import datetime
import streamlit as st
import pandas as pd 
import joblib
</code></pre>
                </div>
            </section>
            <!-- Fim das Bibliotecas-->

            <!-- Etapas do Projeto -->
            <section>
                <h2>Etapas do Projeto</h2>
                <p>O projeto foi divido em duas fases principais: An√°lise e Treinamento do Modelo (Jupyter Notebook) e Deployment com Streamlit.</p>

                <!-- Destrinchando o conte√∫do do Projeto-->
                <ul>
                    <!-- Fase 1-->
                    <li>
                        <h3>Fase 1: An√°lise e Treinamento do Modelo (Jupyter Notebook)</h3>
                        
                        <p>O arquivo <strong><code>analysis_model.ipynb</code></strong> cont√©m todo o c√≥digo utilizado nessa primeira fase.</p>
                        <br>
                        <h4>Base de Dados</h4>
                        <p>Vou come√ßar falando sobre a base de dados utilizadas, assim como no Projeto Pok√©mon em meu portf√≥lio, este tamb√©m utilizou uma base de dados vinda do Kaggle. Voc√™ pode dar uma olhada neste clicando neste <a href="https://www.kaggle.com/datasets/amanalisiddiqui/fraud-detection-dataset?resource=download">link</a>.</p>
                        <p>A base de dados √© um arquivo no formato .CSV que cont√©m dados referentes √† an√°lise de detec√ß√£o de fraudes. Essa base de dados cont√©m dados sobre o remetente (Origem) e o destinat√°rio (Destino) das transa√ß√µes.</p>
                        <p>A base de dados cont√©m muitas colunas, por√©m para este projeto especificamente, irei utilizar apenas algumas colunas. Veja abaixo quais colunas irei utilizar e o que cada uma dela armazena:</p>

                        <!-- Explica√ß√£o do Conte√∫do das Colunas -->
                        <ul>
                            <li>
                                <p>Type
                                <br>
                                Tipo de Dado: Categ√≥rica<br>
                                Descri√ß√£o: Tipo de transa√ß√£o, exemplo: Cash-out, Pagamento, Transfer√™ncia, Dep√≥sito.<br>
                                Uso no Projeto: Muito importante, visto que alguns tipos de transa√ß√µes fraudulentas possuem um tipo de transa√ß√£o favorito para aplicar os golpes.
                                </p>
                            </li>

                            <li>
                                <p>Amount
                                <br>
                                Tipo de Dado: Num√©rica<br>
                                Descri√ß√£o: Valor da transa√ß√£o em moeda local<br>
                                Uso no Projeto: O valor da transa√ß√£o √© um forte indicador de fraude.
                                </p>
                            </li>

                            <li>
                                <p>OldBalanceOrg
                                <br>
                                Tipo de Dado: Num√©rica<br>
                                Descri√ß√£o: Saldo inicial do remetente (Origem) antes da transa√ß√£o.<br>
                                Uso no Projeto: Inidica a capacidade financeira do remetente.
                                </p>
                            </li>

                            <li>
                                <p>NewBalanceOrig
                                <br>
                                Tipo de Dado: Num√©rica<br>
                                Descri√ß√£o: Novo salodo do remetente (Origem) ap√≥s a transa√ß√£o.<br>
                                Uso no Projeto: Permite a valida√ß√£o de inconsist√™ncias de saldo.
                                </p>
                            </li>

                            <li>
                                <p>OldBalnceDest
                                <br>
                                Tipo de Dado: Num√©rica<br>
                                Descri√ß√£o: Saldo inicial do destinat√°rio (Destino) antes da transa√ß√£o.<br>
                                Uso no Projeto: Ajuda a identificar contas destino com saldos suspeitos.
                                </p>
                            </li>

                            <li>
                                <p>NewBalanceDest
                                <br>
                                Tipo de Dado: Num√©rica<br>
                                Descri√ß√£o: Novo saldo do destinat√°rio (Destino) ap√≥s a transa√ß√£o.<br>
                                Uso no Projeto: Completa a verifica√ß√£o de saldos.
                                </p>
                            </li>

                            <li>
                                <p>isFraud
                                <br>
                                Tipo de Dado: Bin√°rio (Target)<br>
                                Descri√ß√£o: 1- Indica que a transa√ß√£o √© fraudulenta -- 0- Indica que a transa√ß√£o √© leg√≠tima.<br>
                                Uso no Projeto: Usada para treinar e avaliar a precis√£o do modelo.
                                </p>
                            </li>
                        </ul>
                        <!-- Fim da Explica√ß√£o do Conte√∫do das Colunas-->

                        <!-- Tipos de Dados-->
                        <p>Mas o que significa cada um desses tipos de dados?</p>

                        <!-- In√≠cio: Dado Categ√≥rico -->
                        <p><strong>Dado Categ√≥rico</strong></p>
                        <p>Dados categ√≥ricos representam qualidades, r√≥tulos ou grupos.. Eles n√£o possuem um valor intrinsecamente num√©rico ou uma ordem matem√°tica.</p>
                        <p>Caracter√≠sticas</p>
                        <ul>
                            <li><p><strong>N√£o s√£o quantitativos: </strong>N√£o √© poss√≠vel realizar opera√ß√µes matem√°ticas com eles de forma significativa.</p>
                            </li>

                            <li><p><strong>Representam Classes: </strong>Os valores pertencem a um conjunto finito de categorias.</p>
                            </li>
                        </ul>

                        <p>Tipos comuns</p>
                        <ul>
                            <li>
                                <p>Tipo de Categoria: Nominal<br>
                                Descri√ß√£o: Categorias sem ordem ou hierarquia.<br>
                                Uso no Projeto: Conte√∫dos da coluna <strong><code>type</code></strong>. N√£o h√° ordem entre eles.
                                </p>
                            </li>

                            <li>
                                <p>Tipo de Categoria: Ordinal<br>
                                Descri√ß√£o: Categorias que possuem uma ordem ou classifica√ß√£o natural.<br>
                                Exemplo de Uso: N√≠vel de satisfa√ß√£o do cliente: "Baixo", "M√©dio" ou "Alto".
                                </p>
                            </li>
                        </ul>
                        <!-- Fim: Dado Categ√≥rico -->
                        
                        <br>

                        <!-- In√≠cio: Dado Num√©rico -->
                        <p><strong>Dado Num√©rico</strong></p>
                        <p>Dados num√©ricos ou quantitativos, representam quantidades, medidas ou contagens e podem ser submetidos a opera√ß√µes matem√°icas.</p>
                        <p>Caracter√≠sticas</p>
                        <ul>
                            <li><p><strong>Quantitativos: </strong>T√™m valor e significado num√©rico.</p></li>
                            <li><p><strong>Escala e Ordem: </strong>Os valores t√™m uma ordem clara e a diferen√ßa entre eles √© significativa.</p></li>
                        </ul>

                        <p>Tipos comuns</p>
                        <ul>
                            <li>
                                <p>Tipo Num√©rico: Cont√≠nuo<br>
                                Descri√ß√£o: Valores que podem assumir qualquer valor dentro de um intervalo, incluindo casas decimais.<br>
                                Uso no Projeto: <strong><code>amount</code></strong> (Quantia da Transa√ß√£o), <strong><code>OldBalanceOrg</code></strong> (Saldos).</p>
                            </li>

                            <li>
                                <p>Tipo Num√©rico: Discreto<br>
                                Descri√ß√£o: Valores que s√£o contagens e s√≥ podem assumir n√∫meros inteiros<br>
                                Exemplo de Uso: N√∫mero de filhos, n√∫mero de acessos a um site.</p>
                            </li>
                        </ul>
                        <!-- Fim: Dado Num√©rico -->

                        <br>

                        <!-- In√≠cio: Dado Bin√°rio -->
                        <p><strong>Dado Bin√°rio</strong></p>
                        <p>S√£o um caso especial de dado categ√≥rico (nominal) onde existem apenas duas categorias poss√≠veis.</p>
                        <p>Caracter√≠sticas</p>
                        <ul>
                            <li><p><strong>Duas Classes: </strong>Os valores s√£o mutuamente exclusivos (sim/n√£o, verdadeiro/falso, 0/1).</p></li>
                            <li><p><strong>Vari√°vel Alvo: </strong>Em ML, s√£o frequentemente usados como a vari√°vel que o modelo tenta prever (vari√°vel target ou alvo) em problemas de classifica√ß√£o bin√°ria.</p></li>
                        </ul>

                        <p>No projeto o dado bin√°rio pode ser encontrado por exemplo na base de dados na coluna <strong><code>isFraud</code></strong>, onde se igual a 1 indica transa√ß√£o fraudulenta e, se igual a 0 indica transa√ß√£o leg√≠tima.</p>

                        <!-- Fim: Dado Bin√°rio -->
                        <!-- Fim do Tipo de Dado-->
                        
                        <p>Agora que entendemos como a base de dados est√° estruturada, vamos seguir com a prepara√ß√£o dos dados para o treinamento do modelo.</p>
                        <br>
                        <!-- In√≠cio: Pr√©-processamento e Pipeline -->
                        <h4>Pr√©-processamento e Pipeline</h4>
                        <p>Essa etapa √© o core de todo Projeto de ML. √â aqui que os dados brutos s√£o transformados em algo que o modelo consegue aprender e garante que a aplica√ß√£o Streamlit funcione corretamente em produ√ß√£o.</p>
                        <p>Mas...</p>
                        <strong>O que √© e como funciona o pr√©-processamento dos dados?</strong>
                        <p>Basicamente √© um conjunto de t√©cnicas aplicadas aos dados brutos para prepar√°-los antes de serem utilizados no treinamento de um modelo de Machine Learning.</p>
                        <p>O objetivo aqui √© garantir que os dados de entrada estejam no formato, escala e qualidade ideias para otimizar o aprendizado e a precis√£o do modelo.</p>

                        <p>Meu projeto foca em duas transforma√ß√µes essenciais:</p>
                        
                        <!-- In√≠cio: Transforma√ß√µes -->
                        <ul>
                            <li>
                                <strong>Transforma√ß√£o de Dados Categ√≥ricos (Encoding)</strong>
                                <strong>A√ß√£o: </strong><p>Lida com a feature <strong><code>type</code></strong> (Pagemento, Transfer√™ncia, Cash_Out, Dep√≥sito).</p>
                                <strong>Problema: </strong><p>Modelos de ML s√≥ entendem n√∫meros, se for passado a palavra "TRANSFER√äNCIA" diretamente, o modelo n√£o saber√° como interpret√°-lo.</p>
                                <strong>Solu√ß√£o: </strong><p>One-Hot Encoding (usando o <strong><code>OneHotEncoder</code></strong> do Scikit-learn).</p>
                                <ul>
                                    <li>
                                        <p>Cria colunas para cada tipo.</p>
                                    </li>
                                    <li>
                                        <p>Exemplo: Uma transa√ß√£o de "TRANSFER√äNCIA" ter√° 1 na coluna <strong><code>type_TRANSFERENCIA</code></strong> e 0 nas demais colunas de tipo.</p>
                                    </li>
                                </ul>
                            </li>

                            <li>
                                <strong>Escalonamento de Dados Num√©ricos (Scaling)</strong>
                                <strong>A√ß√£o: </strong><p>Lida com as features num√©ricas como <strong><code>amount, oldbalanceOrg, newbalanceOrig, OldbalanceDest, newbalanceDest</code></strong>.</p>
                                <strong>Problema: </strong><p>O valor da <strong><code>amount</code></strong> pode ser de R$ 100,00 ou R$ 1.000.000,00, uma diferen√ßa enorme. Sem escalonamento, o modelo pode dar peso indevido a features com maior magnitude.</p>
                                <strong>Solu√ß√£o: </strong><p>Standard Scaling (usando o <strong><code>StandardScaler</code></strong> do Scikit-learn).</p>
                                <ul>
                                    <li>
                                        <p>Esse m√©todo padroniza os dados, subtraindo a m√©dia e dividindo pelo desvio padr√£o (Z-score).</p>
                                    </li>
                                    <li>
                                        <p>Resultado: Todas as features num√©ricas s√£o reescaladas para ter m√©dia zero e desvio-padr√£o um, garantindo que o modelo trate todas elas com a mesma import√¢ncia em termos de escala.</p>
                                    </li>
                                </ul>
                            </li>
                        </ul>
                        <!-- Fim: Transforma√ß√µes -->
                        <!-- Fim: Pr√©-processamento e Pipeline -->
                        <br>
                        <!-- In√≠cio: Conceito de Pipeline -->
                        <h4>O Conceito de Pipeline (No Scikit-learn)</h4>
                        <p>O Pipeline √© uma ferramenta do Scikit-learn que permite sequenciar v√°rias etapas de processamento de dados e o modelo final em um √∫nico objeto coerente.</p>
                        <p>O arquivo <strong><code>fraud_detection_pipeline.pkl</code></strong> √© esse objeto serializado.</p>
                        
                        <br>
                        <strong>Vantagens Chave do Pipeline</strong>
                        <br>
                        <strong>A. Preven√ß√£o de Vazamento de Dados (Data Leakage)</strong>
                        <p>O Pipeline garante que as transforma√ß√µes sejam calculadas apenas nos dados de treinamento e aplicadas consistentemente nos dados de teste e de produ√ß√£o. Isso evita o vazamento de informa√ß√µes do conjunto de teste para o conjunto de treinamento, o que inflaria artificialmente a precis√£o do seu modelo.</p>

                        <br>
                        <strong>B. Organiza√ß√£o e Reutiliza√ß√£o (MLOps)</strong>
                        <p>Essa √© a maior vantagem na etapa de Deployment:</p>
                        <ul>
                            <li>
                                <strong>Treinamento: </strong><p>Voc√™ treina o pipeline inteiro em uma √∫nica chamada (<strong><code>pipeline.fit(X_train, y_train)</code></strong>), e ele aprende automaticamente os par√¢metros de codifica√ß√£o.</p>
                            </li>
                            <li>
                                <strong>Deployment: </strong><p>Voc√™ salva o pipeline inteiro (incluindo o pr√©-processamento e o modelo treinado) em um √∫nico arquivo (<strong><code>fraud_detection_pipeline.pkl</code></strong>) usando o <strong><code>joblib.dump()</code></strong>.</p>
                            </li>
                            <li>
                                <strong>App Streamlit: </strong><p>O script <strong><code>fraud_detection.py</code></strong> carrega este √∫nico arquivo com <strong><code>joblib.load()</code></strong>. Quando o usu√°rio insere novos dados, simplesmente chamo <strong><code>pipeline.predict(input_data)</code></strong>, e o pipeline aplica exatamente as mesmas transforma√ß√µes aprendidas no treinamento antes de passar os dados para o modelo.</p>
                            </li>
                        </ul>

                        <br>
                        <strong>Arquitetura do Pipeline (ColumnTransformer)</strong>
                        <p>O Pipeline utiliza o <strong><code>ColumnTransformer</code></strong> para lidar com colunas de diferentes tipos de dados simultaneamente:</p>
                        <ul>
                            <li>
                                <strong>ColumnTransformer: </strong><p>Aplica o <strong><code>StandardScaler</code></strong> apenas nas colunas num√©ricas (<strong><code>amount, oldbalanceOrg, ...</code></strong>).</p>
                            </li>

                            <li>
                                <strong>Transformador 'num': </strong><p>Aplica o <strong><code>OneHotEncoder</code></strong> apenas na coluna categ√≥rica (<strong><code>type</code></strong>).</p>
                            </li>

                            <li>
                                <strong>Modelo Final: </strong><p>Ap√≥s as colunas serem transformadas e combinadas, o Pipeline passa o resultado para o algoritmo de classifica√ß√£o para a previs√£o final.</p>
                            </li>
                        </ul>
                        <!-- Fim: Conceito de Pipeline -->

                        <!-- In√≠cio: Recursos Num√©ricos-->
                        <h5>Recursos Num√©ricos</h5>
                        <p>O <strong><code>StandardScaler</code></strong> √© uma t√©cnica de scaling crucial para as colunas que representam valores monet√°rios e saldos na base de dados: <strong><code>amount, oldbalanceOrg, newbalanceOrig, oldbalanceDest, newbalanceDest</code></strong>.</p>
                        
                        <strong>O que o StandardScaler faz?</strong>
                        <p>O objetivo √© padronizar a distribui√ß√£o dos dados de forma que eles tenham: </p>
                        <ul>
                            <li>M√©dia (Œº) igual a zero.</li>
                            <li>Desvio-padr√£o (œÉ) igual a um.</li>
                        </ul>

                        <p>Ele realiza essa transforma√ß√£o aplicando a f√≥rmula abaixo a cada ponto de dados (ùë•).</p>

                        <img src="img/projetos/analise-de-fraude/formula-1.jpg">

                        <p>Onde:</p>
                        <ul>
                            <li>ùë• √© o valor original da feature.</li>
                            <li>Œº √© a m√©dia dessa feature calculada no conjunto de treinamento.</li>
                            <li>œÉ √© o desvio-padr√£o dessa feature calculado no conjunto de treinamento.</li>
                        </ul>

                        <br>
                        <p>Mas...</p>

                        <strong>O que s√£o Features afinal?</strong>
                        <p>√â uma vari√°vel individual mensur√°vel que pode ser utilizada para descrever o fen√¥meno a ser analisado ou previsto. Basicamente, √© uma coluna na base de dados utilizada.
                        Como se trata das informa√ß√µes armazenadas na base de dados, quanto melhor a qualidade das informa√ß√µes, melhor √© o resultado final. 
                        </p>

                        <br>

                        <strong>Por que usar o StandardScaler?</strong>
                        <br>
                        <strong>A. Evitar que Features Maiores Dominem</strong>
                        <p>Features num√©ricas t√™m magnitudes bem diferentes.</p>
                        <p>Modelos baseados em dist√¢ncia, como por exemplo Regress√£o Log√≠stica, K-Nearest Neighbors, Support Vector Machines, entre outros, s√£o sens√≠veis √† escala.
                        Se uma feature tem valores de 10.000 a 1.000.000 e outra de 1 a 10, o modelo ter√° uma tend√™ncia a dar um peso muito maior √† feature com os valores maiores.
                        </p>
                        <p>Ao padronizar os dados, estamos garantindo que a import√¢ncia de uma feature no modelo seja determinada pela sua relev√¢ncia preditiva, e n√£o simplesmente pelo tamanho dos seus valores.</p>

                        <strong>B. Otimiza√ß√£o do Algoritmo</strong>
                        <p>A padroniza√ß√£o dos dados melhora a converg√™ncia e a velocidade de treinamento de muitos algoritmos de ML, especialmente aqueles que usam otimiza√ß√£o baseada em gradiente, como Regress√£o Log√≠stica e Redes Neurais.</p>
                        <!-- Fim: Recursos Num√©ricos-->
                        
                        <br>

                        <!-- In√≠cio: Recursos Categ√≥ricos -->
                        <h5>Recursos Categ√≥ricos</h5>
                        <p>O <strong><code>OneHotEncoder</code></strong> √© a t√©cnica padr√£o para transformar dados categ√≥ricos nominais (que n√£o possuem ordem) em um formato que o modelo de Machine Learning consegue processar numericamente.</p>

                        <strong>O que o OneHotEncoder faz?</strong>
                        <p>O codificador pega a coluna categ√≥rica e a divide em v√°rias colunas bin√°rias, uma para cada categoria √∫nica presente nos dados de treinamento.</p>
                        <p>Exemplo</p>
                        <div class="code-container">
                                <pre><code class="language-python">Transa√ß√£o | type (Original) | type_TRANSFER√äNCIA | type_PAGAMENTO | type_CASH_OUT | type_DEP√ìSITO
A          TRANSFER√äNCIA        1                      0                  0            0
B          PAGAMENTO            0                      1                  0            0
C,         CASH_OUT             0                      0                  1            0</code></pre>
                            </div>

                        <strong>Por que usar o OneHotEncoder?</strong>
                        <br>
                        <strong>A. Impedir o Reconhecimento de Ordem</strong>
                        <p>Se tentarmos codificar <strong>TRANSFER√äNCIA</strong> como 1, <strong>PAGAMENTO</strong> como 2, <strong>CASH_OUT</strong> como 3, etc (uma t√©cnica chamada Label Encoding),
                        estar√≠amos implicitamente ensinando o modelo que a transa√ß√£o 3 √© maior ou tem uma ordem mais alta que a transa√ß√£o 1.</p>
                        <p>Como as categorias de transa√ß√£o n√£o t√™m uma ordem inerente, essa codifica√ß√£o falsa iria distorcer o aprendizado do modelo. Por isso o One-Hot Encoding resolve isso. 
                        Ele garante que cada categoria seja tratada como um atributo independente.
                        </p>

                        <strong>B. Indicar a Presen√ßa (ou Aus√™ncia)</strong>
                        <p>Quando criamos colunas bin√°rias, o modelo pode aprender que um valor de "1" em <strong><code>type_TRANSFERENCIA</code></strong> tem uma rela√ß√£o espec√≠fica com o r√≥tulo <strong><code>isFraud = 1</code></strong>,
                        enquanto um valor "1" em <strong><code>type_PAGAMENTO</code></strong> pode ter uma correla√ß√£o com <strong><code>isFraud = 0</code></strong>.
                        Essa √© a forma mais eficaz de extrair poder preditivo de features categ√≥ricas.</p>

                        <!-- Fim: Recursos Categ√≥ricos -->
                        
                        <br>

                        <!-- In√≠cio: Treinamento -->
                        <h4>Treinamento do Modelo</h4>
                        <p>O treinamento √© o processo pelo qual o algoritmo de ML examina o conjunto de dados do treino, ajustando seus par√¢metros internos para encontrar o padr√£o que melhor
                        relaciona as features √† vari√°vel alvo.
                        </p>

                        <strong>Fases do treinamento:</strong>
                        <br>
                        <strong>A. Divis√£o de Dados (Train-Test-Split)</strong>
                        <p>Antes de treinar, o conjunto de dados original √© dividido em duas partes essenciais:</p>
                        <br>
                        <ul>
                            <li>
                                <strong>1. Conjunto de Treinamento (Train Set): </strong><p>A maior parte dos dados (ex.: 70% ou 80%) que o modelo usa para aprender padr√µes.</p>
                            </li>

                            <li>
                                <strong>2. Conjunto de Teste (Test Set): </strong><p>A por√ß√£o de dados (ex.: 20% ou 30%) que o modelo nunca v√™ durante o treinamento. Ele √© reservado para a fase de avalia√ß√£o,
                                garantindo um teste imparcial da performance do modelo.
                                </p>
                            </li>
                        </ul>

                        <strong>B. Execu√ß√£o do Pipeline</strong>
                        <p>O comando central dessa fase √©: <strong><code>pipeline.fit(X_train, y_train)</code></strong>:</p>
                        <ul>
                            <li>
                                <p>O pipeline executa o pr√©-processamento (aplicando o <strong><code>StandardScaler</code></strong> e <strong><code>OneHotEncoder</code></strong>)
                                nos dados de treinamento (<strong><code>X_train</code></strong>).</p>
                            </li>

                            <li>
                                <p>Os dados transformados s√£o ent√£o enviados ao algoritmo de ML.</p>
                            </li>

                            <li>O modelo usa o r√≥tulo verdadeiro (<strong><code>y_train</code></strong>, a coluna <strong><code>isFraud</code></strong>) para ajustar seus pesos, aprendendo a distiguintes entre transa√ß√µes fraudulentas e leg√≠timas.</li>
                        </ul>
                        <!-- Fim: Treinamento -->
                        <br>
                        <br>
                        <!-- In√≠cio: Avalia√ß√£o do Modelo -->
                        <h4>Avalia√ß√£o do Modelo</h4>
                        <p>A avalia√ß√£o √© a etapa de verifica√ß√£o, onde usamos o conjunto de dados novos para saber o qu√£o bem o modelo aprendeu.</p>

                        <strong>A. Gera√ß√£o de Predi√ß√µes</strong>
                        <p>O modelo √© solicitado a fazer previs√µes nos dados de teste (<strong><code>y_pred = pipeline.predict(X_test)</code></strong>).</p>
                        <ul>
                            <li>
                                <p>O pipeline aplica as mesmas transforma√ß√µes aprendidas no treinamento aos dados de teste (<strong><code>X_test</code></strong>).</p>
                            </li>

                            <li>
                                <p>O modelo gera um r√≥tulo previsto (<strong><code>y_pred</code></strong>) para cada transa√ß√£o no conjunto de teste.</p>
                            </li>
                        </ul>

                        <strong>B. Matriz de Confus√£o</strong>
                        <p>√â a primeira e mais importante ferramenta de avalia√ß√£o. Ela compara as previs√µes do modelo (<strong><code>y_pred</code></strong>) com os resultados 
                        reais (<strong><code>y_test</code></strong>).</p>

                        <ul>
                            <li>
                                <strong>Categoria: </strong><p>Previsto Negativo</p>
                                <strong>Real Negativo (Leg√≠timo)</strong>
                                <br>
                                <p><strong>Verdadeiro Negativo (VN): </strong>Transa√ß√µes leg√≠timas corretamente identificadas.</p>
                                <strong>Real Positivo (Fraude)</strong>
                                <br>
                                <p><strong>Falso Negativo (FN): </strong>O erro mais perigoso. Transa√ß√µes de fraude que o modelo perdeu.</p>
                            </li>

                            <li>
                                <strong>Categoria: </strong><p>Previsto Positivo</p>
                                <strong>Falso Positivo (FP): </strong>
                                <br>
                                <p>Transa√ß√µes leg√≠timas classificadas incorretamente como fraude.</p>
                                <strong>Real Positivo (Fraude): </strong>
                                <br>
                                <p><strong>Verdadeiro Positivo (VP): </strong>Transa√ß√µes de fraude corretamente identificadas.</p>
                            </li>
                        </ul>

                        <strong>C. M√©trica de Precis√£o</strong>
                        <p>A precis√£o (Accuracy) √© a m√©trica que mede a propor√ß√£o total de previs√µes corretas feitas por um modelo em rela√ß√£o ao n√∫mero total de casos avaliados.</p>
                        <p>Este projeto possui acur√°cia de 94,71%.</p>
                        <p>F√≥rmula: </p>
                        <img src="img/projetos/analise-de-fraude/formula-2.jpg">
                        <br>
                        <br>
                        <strong>O que isso significa?</strong>
                        <p>No conjunto de dados de teste (que o modelo nunca viu), ele classificou corretamente 94,71% das transa√ß√µes.</p>

                        <strong>Considera√ß√£o Cr√≠tica para Fraude (Imbalance)</strong>
                        <p>Em um problema de detec√ß√£o de fraude, a acur√°cia √© uma m√©trica importante, por√©m n√£o √© a √∫nica. Como o dataset √© desequilibrado, √© important√≠ssimo analisar: </p>
                        <ul>
                            <li>
                                <strong>1. Recall (Sensibilidade): </strong><p>Qual a porcentagem de todas as fraudes reais que o modelos conseguiu detectar? (Minimizar Falsos Negativos)</p>
                            </li>
                            <li>
                                <strong>2. Precision: </strong><p>Quando o modelo diz que √© fraude, qual a chance de ele estar certo? (Minimizar Falsos Positivos)</p>
                            </li>
                        </ul>

                        <p>Um projeto de boa qualidade sempre precisa balancear a Acur√°cia com o Recall para garantir que as fraudes perigosas (FN) sejam minimizadas, mesmo que isso signifique aceitar um pequeno aumento nos alertas falsos (FP).</p>
                        <!-- Fim: Avalia√ß√£o do Modelo -->
                        <br>
                        <!-- In√≠cio: Salvamento do Pipeline -->
                        <h4>Salvamento do Pipeline</h4>
                        <p>O salvamento do pipeline √© a√ß√£o de seializar o objeto Python completo do Scikit-learn que cont√©m todas as regras do modelo treinado em um √∫nico arquivo bin√°rio (<strong><code>.pkl</code></strong> ou <strong><code>.joblib</code></strong>).</p>

                        <div class="code-container">
                            <pre><code class="language-python">joblib.dump(pipeline, "fraud_detection_pipeline.pkl")</code></pre>
                        </div>

                        <p>Este c√≥digo resulta na cria√ß√£o do arquivo Pickle, um arquivo que permite converter objetos complexos da mem√≥ria (como modelos inteiros do Scikit-learn) em um fluxo de bytes que pode ser salvo, carregado e recuperado em disco sem a necessidade de retreinar o modelo.</p>
                        <br>
                        <strong>1. O que exatamente est√° sendo salvo?</strong>
                        <p>Quando o objeto pipeline √© salvo, n√£o est√° sendo salvo apenas o c√≥digo python, mas sim tdodo o aprendizado de m√°quina do modelo e das regras de transforma√ß√£o:</p>
                        <ul>
                            <li>
                                <strong>Componente salvo: </strong><p>StandardScaler</p>
                                <strong>Conte√∫do Espec√≠fico: </strong><p>M√©dia (Œº) e Desvio-padr√£o (œÉ) calculados em cada coluna num√©rica do conjunto de treino.</p>
                                <strong>Fun√ß√£o na Previs√£o: </strong><p>Garante que os novos dados inseridos no Streamlite sejam escalonados exatamente com a mesma refer√™ncia usada no treinamento.</p>
                            </li>

                            <li>
                                <strong>Componente Salvo: </strong><p>OneHotEncoder</p>
                                <strong>Conte√∫do Espec√≠fico: </strong><p>A lista exata de categorias vistas na coluna <strong><code>type</code></strong>.</p>
                                <strong>Fun√ß√£o na Previs√£o: </strong><p>Garante que o input do Streamlit seja codificado nas mesmas colunas que o modelo espera, tratando uma "TRANSFER√äNCIA" nova da mesma forma que a "TRANSFER√äNCIA" de treino.</p>
                            </li>

                            <li>
                                <strong>Componente Salvo: </strong><p>Modelo de Classifica√ß√£o</p>
                                <strong>Conte√∫do Espec√≠fico: </strong><p>Os pesos (par√¢metros) finais que o modelo ajustou durante o treinamento para fazer a classifica√ß√£o.</p>
                                <strong>Fun√ß√£o na Previs√£o: </strong><p>√â o c√≥digo que efetivamente toma a decis√£o final de previs√£o.</p>
                            </li>
                        </ul>

                        <br>
                        <strong>2. A ferramenta: <code>joblib</code></strong>
                        <p>Utilizei a biblioteca <strong><code>joblib</code></strong> para serializa√ß√£o.</p>
                        <strong>Por que n√£o utilizei a biblioteca <code>pickle</code>?</strong>
                        <ul>
                            <li>
                                <p><strong><code>joblib</code></strong> √© o m√©todo indicado para serializar objetos que cont√©m muitos arrays de dados (como os pesos do modelo e dados internos do StandardScaler), porque √© mais eficiente para objetos que cont√™m dados NumPy grandes, como √© o caso dos modelos do Scikit-learn.</p>
                            </li>
                        </ul>
                        
                        <br>
                        <strong>3. A import√¢ncia estrat√©gica (MLOps)</strong>
                        <p>O salvamento do pipeline √© a etapa de MLOps que torna um projeto de ML realmente funcional e poss√≠vel de colocar em produ√ß√£o.</p>

                        <strong>A. Garantia de Consist√™ncia (End-to-End)</strong>
                        <p>Se as etapas de treinamento do modelo, o pr√©-processamento e o salvamento do modelo fossem salvos separadamente, haveria o risco de algo n√£o ser aplicado corretamene no Streamlit.</p>
                        <p>Salvando o Pipeline estou garantindo que a previs√£o do modelo √© gerada pela aplica√ß√£o do pr√©-processamento corretamente seguido do modelo treinado.</p>
                        <img src="img/projetos/analise-de-fraude/pipeline.jpg">
                        <br>
                        <br>

                        <strong>B. Simplifica√ß√£o do Deployment</strong>
                        <p>A aplica√ß√£o Streamlit (<strong><code>fraud_detection.py</code></strong>) possui o c√≥digo necess√°rio para colcar o modelo no ar.</p>
                        <p>Na Fase 2 irei falar um pouco mais detalhadamente sobre o deployment. Voc√™ pode pular clicando neste <a href="#">link</a>.</p>
                        <!-- Fim: Salvamento do Pipeline -->
                        
                    </li>
                    <!-- Fim Fase 1-->

                    <br>
                    <p>Antes de avan√ßar para a Fase 2 do projeto, veja abaixo a explica√ß√£o do c√≥digo utilizado para o treinamento do modelo de ML.</p>
                    <p>Caso queira pular essa parte, pode ir direto para a <a href="#">Fase 2</a>.</p>
                    <br>
                    <br>

                    <!-- In√≠cio: Apresenta√ß√£o do C√≥digo -->
                    <li>
                        <h3>C√≥digo de Treinamento do Modelo</h3>

                        <p>Sempre costumo iniciar minhas an√°lises explorat√≥rias verificando o tipo de cada uma das colunas da base de dados.</p>
                        <div class="code-container">
                            <pre><code class="language-python">df.info()</code></pre>
                        </div>

                        <div class="code-container">
                            <pre><code class="language-bash">
class 'pandas.core.frame.DataFrame'
RangeIndex: 6362620 entries, 0 to 6362619
Data columns (total 11 columns):
 #   Column          Dtype  
---  ------          -----  
 0   step            int64  
 1   type            object 
 2   amount          float64
 3   nameOrig        object 
 4   oldbalanceOrg   float64
 5   newbalanceOrig  float64
 6   nameDest        object 
 7   oldbalanceDest  float64
 8   newbalanceDest  float64
 9   isFraud         int64  
 10  isFlaggedFraud  int64  
dtypes: float64(5), int64(3), object(3)
                            </code></pre>
                        </div>

                        <br>
                        
                        <p>Sigo validando o nome de cada coluna.</p>
                        <div class="code-container">
                            <pre><code class="language-python">df.columns</code></pre>
                        </div>

                        <div class="code-container">
                            <pre><code class="language-bash">Index(['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig',
'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud',
'isFlaggedFraud'],
dtype='object')</code></pre>
                        </div>

                        <br>

                        <p>Quantidade de conte√∫do na coluna alvo. 
                        <br>
                            <ul>
                                <li><strong><code>df["isFraud"]</code></strong>: Seleciona a vari√°vel alvo do DataFrame.</li>
                                <li><strong><code>.value_counts()</code></strong>: retorna uma S√©rie que cont√©m a contagem de ocorr√™ncias de valores √∫nicos na coluna.</li>
                            </ul>
                        </p>
                        <div class="code-container">
                            <pre><code class="language-python">df["isFraud"].value_counts()</code></pre>
                        </div>

                        <div class="code-container">
                            <pre><code class="language-bash">isFraud
0    6354407
1       8213
Name: count, dtype: int64</code></pre>
                        </div>

                        <br>

                        <p>Tr√™s m√©todos aplicados em sequ√™ncia com o objetivo de retornar o n√∫mero total de valores nulos.</p>

                        <p>
                            <ul>
                                <li><strong><code>.isnull()</code></strong>: Aplicado em todo o DataFrame e transforma o DataFrame em um novo DataFrame com valores booleanos, onde o valor original era NaN, o resultado √© True, e, onde o valor original era v√°lido, o resulado √© False.</li>

                                <li><strong><code>.sum()</code></strong> (Primeira Soma): Aplicado apenas nas colunas do DataFrame booleano. Ao somar valores booleanos, True √© tratado como 1 e False √© tratado como 0.</li>

                                <li><strong><code>.sum()</code></strong> (Segunda Soma): Aplicado apenas na S√©rie resultante da soma anterior. Todos os valores da S√©rie s√£o somados e apresentados em apenas um √∫nico n√∫mero inteiro que representa </li>
                            </ul>
                        </p>

                        <div class="code-container">
                            <pre><code class="language-python">df.isnull().sum().sum()</code></pre>
                        </div>

                        <div class="code-container">
                            <pre><code class="language-bash">np.int64(0)</code></pre>
                        </div>

                        <br>

                        <p><strong><code>.shape</code></strong> √© um atributo que retorna uma tupla informando a quantidade de linhas e de colunas respectivamente.</p>

                        <div class="code-container">
                            <pre><code class="language-python">df.shape</code></pre>
                        </div>

                        <div class="code-container">
                            <pre><code class="language-bash">(6362620, 11)</code></pre>
                        </div>

                        <br>

                        <p>O c√≥digo abaixo calcula a porcentagem exata de fraudes no conjunto de dados.</p>

                        <div class="code-container">
                            <pre><code class="language-python">round((df["isFraud"].value_counts()[1] / df.shape[0]) * 100,2)</code></pre>
                        </div>

                        <div class="code-container">
                            <pre><code class="language-bash">np.float64(0.13)</code></pre>
                        </div>

                        <p>Vou destrinchar o c√≥digo acima: </p>
                        <ul>
                            <li>
                                <strong><code>df["isFraud"].value_counts()[1]</code></strong>
                                <ul>
                                    <li>
                                        <strong><code>.value_counts()</code>:</strong> <p>A fun√ß√£o conta quantas vezes 0 e 1 aparecem.</p>
                                    </li>
                                    <li>
                                        <strong><code>[1]</code>:</strong> <p>Aqui eu acesso especificamente a contagem do √≠ndice 1, ou seja, estou isolando apenas o n√∫mero total de casos de fraude.</p>
                                    </li>
                                </ul>
                            </li>

                            <li>
                                <strong><code>df.shape[0]</code></strong>
                                <ul>
                                    <li>
                                        <strong><code>shape</code>:</strong> <p>Retorna a quantidade de linhas e colunas.</p>
                                    </li>
                                    <li>
                                        <strong><code>[0]</code>:</strong> <p>Pego o primeiro valor da tupla, que √© o n√∫mero total de registros no DataFrame.</p>
                                    </li>
                                </ul>
                            </li>

                            <li>
                                <strong><code>(df["isFraud"].value_counts()[1] / df.shape[0]) * 100</code></strong>
                                <ul>
                                    <li>Aqui estou fazendo um c√°lculo: (Total de Fraudes / Total de Transa√ß√µes) * 100. <br> Isso transforma a propor√ß√£o decimal em uma porcentagem.</li>
                                </ul>
                            </li>

                            <li>
                                <strong><code>round(..., 2)</code></strong>
                                <ul>
                                    <li>
                                        <strong><code>round()</code>:</strong> <p>Fun√ß√£o padr√£o do Python para arredondamento de valores.</p>
                                    </li>
                                    <li>
                                        <strong><code>2</code>:</strong> <p>Indico que o resultado deve conter apenas duas casas decimais.</p>
                                    </li>
                                </ul>
                            </li>
                        </ul>

                        <br>

                        <p>Agora quero visualizar algumas informa√ß√µes</p>

                        <div class="code-container">
                            <pre><code class="language-python">df["type"].value_counts().plot(kind="bar", title="Tipos de Transa√ß√£o", color="skyblue")
plt.xlabel("Tipo de transa√ß√£o")
plt.ylabel("Quantidade")
plt.show()</code></pre>
                        </div>

                        <p>Vou destrinchar o c√≥digo: </p>

                        <ul>
                            <li>
                                <strong><code>df["type"].value_counts().plot(kind="bar", title="Tipos de Transa√ß√£o", color="skyblue")</code>:</strong>
                                <ul>
                                    <li>
                                        <strong><code>.plot()</code></strong>
                                        <p>O comando indica que dever√° ser apresentado um gr√°fico.</p>
                                    </li>

                                    <p>Mas, al√©m de indicar que quero ver um gr√°fico, preciso adicionar argumentos dentro dessa fun√ß√£o para que apresenta√ß√£o fique como espero: </p>

                                    <li>
                                        <strong><code>kind = "bar"</code></strong>
                                        <p>Aqui estou indicando que o gr√°fico deve ser no formato de Barras.</p>
                                    </li>

                                    <li>
                                        <strong><code>title = "Tipos de Transa√ß√£o</code></strong>
                                        <p>Indico o t√≠tulo do gr√°fico</p>
                                    </li>

                                    <li>
                                        <strong><code>color = "skyblue"</code></strong>
                                        <p>Indico qual a cor das barras no gr√°fico.</p>
                                    </li>
                                </ul>
                            </li>

                            <li>
                                <strong><code>plt.xlabel("Tipo de transa√ß√£o")</code></strong>
                                <br>
                                <strong><code>plt.ylabel("Quantidade")</code></strong>
                                <ul>
                                    <li>Fun√ß√µes vindas da biblioteca <strong><code>matplotlib.pyplot</code></strong> adicionam legendas aos eixos X e Y.</li>
                                </ul>
                            </li>
                            <br>
                            <li>
                                <strong><code>plt.show()</code></strong>
                                <p>Essa fun√ß√£o limpa as informa√ß√µes de log do sistema e exibe apenas a figura final na tela evitando que apare√ßam textos t√©cnicos em cima do gr√°fico.</p>
                            </li>
                        </ul>

                        <img src="img/projetos/analise-de-fraude/grafico-de-barra-1.jpg">

                        <br>

                        <p>Al√©m de analisar a quantidade de transa√ß√µes, quero ver a taxa de periculosidade para cada tipo de opera√ß√£o.</p>

                        <div class="code-container">
                            <pre><code class="language-python">fraude_por_tipo = df.groupby("type")["isFraud"].mean().sort_values(ascending=False)
fraude_por_tipo.plot(kind="bar", title="Percentual de Fraude por Tipo", color="salmon")
plt.ylabel("Percentual de Fraude por Tipo")
plt.show()</code></pre>
                        </div>

                        <p>Vou destrinchar o c√≥digo: </p>

                        <ul>
                            <li>
                                <strong><code>groupby() e mean()</code></strong><br>
                                <strong>fraude_por_tipo = df.groupby("type")</strong><br>
                                <strong>["isFraud"].mean().sort_values(ascending=False)</strong>
                                <p>O c√°lculo gira em torno dessas duas fun√ß√µes e faz tr√™s coisas fundamentais: </p>
                                <ul>
                                    <li>
                                        <strong><code>df.groupby("type")</code>: </strong>
                                        <p>Essa fun√ß√£o tem o objetivo de dividir a coluna filtrando suas informa√ß√µes em grupos, por exemplo: (PAGAMENTO, TRANSFER√äNCIA, etc.)</p>
                                    </li>

                                    <li>
                                        <strong><code>["isFraud"].mean()</code></strong>
                                        <p>A coluna <strong><code>isFraud</code></strong> s√≥ cont√©m os valores 0 e 1. Calcular a m√©dia √© o mesmo que calcular a propor√ß√£o de fraudes.</p>
                                        <ul>
                                            <li>
                                                Por exemplo:
                                                <br>
                                                Se em 100 transa√ß√µes de 'TRANSFER√äNCIA', 10 forem fraudes, a m√©dia ser√° $10/100 = 0.10$ (ou 10% de taxa de fraude).
                                            </li>
                                        </ul>
                                    </li>

                                    <li>
                                        <strong><code>.sort_values(ascending=False)</code></strong>
                                        <p>A fun√ß√£o organiza os resultados do maior para o menor, dessa forma, os tipos de transa√ß√£o mais perigosos ficam no topo da lista.</p>
                                    </li>
                                </ul>
                            </li>

                            <li>
                                <strong><code>fraude_por_tipo.plot(kind="bar", title="Percentual de Fraude por Tipo", color="salmon")</code></strong>
                                <p>Novamente tenho o objetivo de apresentar um gr√°fico de barras na tela</p>
                            </li>
                        </ul>

                        <img src="img/projetos/analise-de-fraude/grafico-de-barra-2.jpg">

                        <br>
                        

                    </li>
                    <!-- Fim: Apresenta√ß√£o do C√≥digo -->

                    <br>
                    <br>
                    <!-- Fase 2 -->
                    <li>
                        <h3>Fase 2: Deployment com Streamlit</h3>

                    </li>
                    <!-- Fim Fase 2-->

                </ul>
                
            </section>


        </main>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-python.min.js"></script>
    </body>
</html>